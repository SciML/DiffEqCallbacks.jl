var documenterSearchIndex = {"docs":
[{"location":"integrating/#Numerical-Integration-Callbacks","page":"Numerical Integration Callbacks","title":"Numerical Integration Callbacks","text":"","category":"section"},{"location":"integrating/","page":"Numerical Integration Callbacks","title":"Numerical Integration Callbacks","text":"Sometimes one may want to solve an integral simultaneously to the solution of a differential equation. For example, assume we want to solve:","category":"page"},{"location":"integrating/","page":"Numerical Integration Callbacks","title":"Numerical Integration Callbacks","text":"u^prime = f(upt)\nh = int_t_0^t_f g(upt) dt","category":"page"},{"location":"integrating/","page":"Numerical Integration Callbacks","title":"Numerical Integration Callbacks","text":"While one can use the ODE solver's dense solution to call an integration scheme on sol(t) after the solve, this can be memory intensive. Another way one can solve this problem is by extending the system, i.e.:","category":"page"},{"location":"integrating/","page":"Numerical Integration Callbacks","title":"Numerical Integration Callbacks","text":"u^prime = f(upt)\nh^prime = g(upt)","category":"page"},{"location":"integrating/","page":"Numerical Integration Callbacks","title":"Numerical Integration Callbacks","text":"with h(t_0) = 0, so then h(t_f) would be the solution to the integral. However, many differential equation solvers scale superlinearly with the equation size and thus this could add an extra cost to the solver process.","category":"page"},{"location":"integrating/","page":"Numerical Integration Callbacks","title":"Numerical Integration Callbacks","text":"The IntegratingCallback allows one to be able to solve such definite integrals in a way that is both memory and compute efficient. It uses the free local interpolation of a given step in order to approximate the Gaussian quadrature for a given step to the order of the numerical differential equation solve, thus achieving accuracy while not requiring the post-solution dense interpolation to be saved. By doing this via a callback, this method is able to easily integrate with functionality that introduces discontinuities, like other callbacks, in a way that is more accurate than a direct integration post solve.","category":"page"},{"location":"integrating/","page":"Numerical Integration Callbacks","title":"Numerical Integration Callbacks","text":"IntegratingCallback","category":"page"},{"location":"integrating/#DiffEqCallbacks.IntegratingCallback","page":"Numerical Integration Callbacks","title":"DiffEqCallbacks.IntegratingCallback","text":"IntegratingCallback(integrand_func,\n    integrand_values::IntegrandValues,\n    cache = nothing)\n\nLet one define a function integrand_func(u, t, integrator) which returns Integral(integrand_func(u(t),t)dt over the problem tspan.\n\nArguments\n\nintegrand_func(out, u, t, integrator) for in-place problems and out = integrand_func(u, t, integrator) for out-of-place problems. Returns the quantity in the integral for computing dG/dp. Note that for out-of-place problems, this should allocate the output (not as a view to u).\nintegrand_values::IntegrandValues is the types that integrand_func will return, i.e. integrand_func(t, u, integrator)::integrandType. It's specified via IntegrandValues(integrandType), i.e. give the type that integrand_func will output (or higher compatible type).\ncache is provided to store integrand_func output for in-place problems. if cache is nothing but the problem is in-place, then integrand_func is assumed to not be in-place and will be called as out = integrand_func(u, t, integrator).\n\nThe outputted values are saved into integrand_values. The values are found via integrand_values.integrand.\n\nnote: Note\nThis method is currently limited to ODE solvers of order 10 or lower. Open an issue if other solvers are required.If integrand_func is in-place, you must use cache to store the output of integrand_func.\n\n\n\n\n\n","category":"function"},{"location":"uncertainty_quantification/#Uncertainty-Quantification","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"","category":"section"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"The following callbacks are designed to help enable uncertainty quantification of the differential equation solutions.","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"ProbIntsUncertainty\nAdaptiveProbIntsUncertainty","category":"page"},{"location":"uncertainty_quantification/#DiffEqCallbacks.ProbIntsUncertainty","page":"Uncertainty Quantification","title":"DiffEqCallbacks.ProbIntsUncertainty","text":"ProbIntsUncertainty(σ, order, save = true)\n\nThe ProbInts method for uncertainty quantification involves the transformation of an ODE into an associated SDE where the noise is related to the timesteps and the order of the algorithm.\n\nArguments\n\nσ is the noise scaling factor. It is recommended that σ is representative of the size of the errors in a single step of the equation. If such a value is unknown, it can be estimated automatically in adaptive time-stepping algorithms via AdaptiveProbIntsUncertainty\norder is the order of the ODE solver algorithm.\nsave is for choosing whether this callback should control the saving behavior. Generally this is true unless one is stacking callbacks in a CallbackSet.\n\nReferences\n\nConrad P., Girolami M., Särkkä S., Stuart A., Zygalakis. K, Probability Measures for Numerical Solutions of Differential Equations, arXiv:1506.04592\n\n\n\n\n\n","category":"function"},{"location":"uncertainty_quantification/#DiffEqCallbacks.AdaptiveProbIntsUncertainty","page":"Uncertainty Quantification","title":"DiffEqCallbacks.AdaptiveProbIntsUncertainty","text":"AdaptiveProbIntsUncertainty(order, save = true)\n\nThe ProbInts method for uncertainty quantification involves the transformation of an ODE into an associated SDE where the noise is related to the timesteps and the order of the algorithm.\n\nAdaptiveProbIntsUncertainty is a more automated form of ProbIntsUncertainty which uses the error estimate from within adaptive time stepping methods to estimate σ at every step.\n\nArguments\n\norder is the order of the ODE solver algorithm.\nsave is for choosing whether this callback should control the saving behavior. Generally this is true unless one is stacking callbacks in a CallbackSet.\n\nReferences\n\nConrad P., Girolami M., Särkkä S., Stuart A., Zygalakis. K, Probability Measures for Numerical Solutions of Differential Equations, arXiv:1506.04592\n\n\n\n\n\n","category":"function"},{"location":"uncertainty_quantification/#Example-1:-FitzHugh-Nagumo","page":"Uncertainty Quantification","title":"Example 1: FitzHugh-Nagumo","text":"","category":"section"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"In this example we will determine our uncertainty when solving the FitzHugh-Nagumo model with the Euler() method. We define the FitzHugh-Nagumo model:","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"using DiffEqCallbacks, OrdinaryDiffEq, Plots\ngr(fmt = :png)\n\nfunction fitz(du, u, p, t)\n    V, R = u\n    a, b, c = p\n    du[1] = c * (V - V^3 / 3 + R)\n    du[2] = -(1 / c) * (V - a - b * R)\nend\nu0 = [-1.0; 1.0]\ntspan = (0.0, 20.0)\np = (0.2, 0.2, 3.0)\nprob = ODEProblem(fitz, u0, tspan, p)","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Now we define the ProbInts callback. In this case, our method is the Euler method and thus it is order 1. For the noise scaling, we will try a few different values and see how it changes. For σ=0.2, we define the callback as:","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"cb = ProbIntsUncertainty(0.2, 1)","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"This is akin to having an error of approximately 0.2 at each step. We now build and solve a EnsembleProblem for 100 trajectories:","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"ensemble_prob = EnsembleProblem(prob)\nsim = solve(ensemble_prob, Euler(), trajectories = 100, callback = cb, dt = 1 / 10)","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Now we can plot the resulting Monte Carlo solution:","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"plot(sim, idxs = (0, 1), linealpha = 0.4)","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"If we increase the amount of error, we see that some parts of the equation have less uncertainty than others. For example, at σ=0.5:","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"cb = ProbIntsUncertainty(0.5, 1)\nensemble_prob = EnsembleProblem(prob)\nsim = solve(ensemble_prob, Euler(), trajectories = 100, callback = cb, dt = 1 / 10)\nplot(sim, idxs = (0, 1), linealpha = 0.4)","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"But at this amount of noise, we can see how we contract to the true solution by decreasing dt:","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"cb = ProbIntsUncertainty(0.5, 1)\nensemble_prob = EnsembleProblem(prob)\nsim = solve(ensemble_prob, Euler(), trajectories = 100, callback = cb, dt = 1 / 100)\nplot(sim, idxs = (0, 1), linealpha = 0.4)","category":"page"},{"location":"uncertainty_quantification/#Example-2:-Adaptive-ProbInts-on-FitzHugh-Nagumo","page":"Uncertainty Quantification","title":"Example 2: Adaptive ProbInts on FitzHugh-Nagumo","text":"","category":"section"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"While the first example is academic and shows how the ProbInts method scales, the fact that one should have some idea of the error in order to calibrate σ can lead to complications. Thus the more useful method in many cases, is the AdaptiveProbIntsUncertainty version. In this version, no σ is required since this is calculated using an internal error estimate. Thus this gives an accurate representation of the possible error without user input.","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Let's try this with the order 5 Tsit5() method on the same problem as before:","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"cb = AdaptiveProbIntsUncertainty(5)\nsol = solve(prob, Tsit5())\nensemble_prob = EnsembleProblem(prob)\nsim = solve(ensemble_prob, Tsit5(), trajectories = 100, callback = cb)\nplot(sim, idxs = (0, 1), linealpha = 0.4)","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"In this case, we see that the default tolerances give us a very good solution. However, if we increase the tolerance a lot:","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"cb = AdaptiveProbIntsUncertainty(5)\nsol = solve(prob, Tsit5())\nensemble_prob = EnsembleProblem(prob)\nsim = solve(ensemble_prob, Tsit5(), trajectories = 100, callback = cb, abstol = 1e-3,\n    reltol = 1e-1)\nplot(sim, idxs = (0, 1), linealpha = 0.4)","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"we can see that the moments just after the rise can be uncertain.","category":"page"},{"location":"uncertainty_quantification/#Example-3:-Adaptive-ProbInts-on-the-Lorenz-Attractor","page":"Uncertainty Quantification","title":"Example 3: Adaptive ProbInts on the Lorenz Attractor","text":"","category":"section"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"One very good use of uncertainty quantification is on chaotic models. Chaotic equations diverge from the true solution according to the error exponentially. This means that as time goes on, you get further and further from the solution. The ProbInts method can help diagnose how much of the timeseries is reliable.","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"As in the previous example, we first define the model:","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"function g(du, u, p, t)\n    du[1] = p[1] * (u[2] - u[1])\n    du[2] = u[1] * (p[2] - u[3]) - u[2]\n    du[3] = u[1] * u[2] - p[3] * u[3]\nend\nu0 = [1.0; 0.0; 0.0]\ntspan = (0.0, 30.0)\np = [10.0, 28.0, 8 / 3]\nprob = ODEProblem(g, u0, tspan, p)","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"and then we build the ProbInts type. Let's use the order 5 Tsit5 again.","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"cb = AdaptiveProbIntsUncertainty(5)","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Then we solve the MonteCarloProblem","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"ensemble_prob = EnsembleProblem(prob)\nsim = solve(ensemble_prob, Tsit5(), trajectories = 100, callback = cb)\nplot(sim, idxs = (0, 1), linealpha = 0.4)","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Here we see that by t about 22 we start to receive strong deviations from the \"true\" solution. We can increase the amount of time before error explosion by using a higher order method with stricter tolerances:","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"tspan = (0.0, 40.0)\nprob = ODEProblem(g, u0, tspan, p)\ncb = AdaptiveProbIntsUncertainty(7)\nensemble_prob = EnsembleProblem(prob)\nsim = solve(ensemble_prob, Vern7(), trajectories = 100, callback = cb, reltol = 1e-6)\nplot(sim, idxs = (0, 1), linealpha = 0.4)","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"we see that we can extend the amount of time until we deviate strongly from the \"true\" solution. Of course, for a chaotic system like the Lorenz one presented here, it is impossible to follow the true solution for long times, due to the fact that the system is chaotic and unavoidable deviations due to the numerical precision of a computer get amplified exponentially.","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"However, not all hope is lost. The shadowing theorem is a strong statement for having confidence in numerical evolution of chaotic systems:","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Although a numerically computed chaotic trajectory diverges exponentially from the true trajectory with the same initial coordinates, there exists an errorless trajectory with a slightly different initial condition that stays near (\"shadows\") the numerically computed one.","category":"page"},{"location":"uncertainty_quantification/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"For more info on the shadowing theorem, please see the book Chaos in Dynamical Systems by E. Ott.","category":"page"},{"location":"steady_state/#Steady-State-Callbacks","page":"Steady State Callbacks","title":"Steady State Callbacks","text":"","category":"section"},{"location":"steady_state/","page":"Steady State Callbacks","title":"Steady State Callbacks","text":"These callbacks are designed to automatically terminate integration when a steady state is reached.","category":"page"},{"location":"steady_state/","page":"Steady State Callbacks","title":"Steady State Callbacks","text":"TerminateSteadyState","category":"page"},{"location":"steady_state/#DiffEqCallbacks.TerminateSteadyState","page":"Steady State Callbacks","title":"DiffEqCallbacks.TerminateSteadyState","text":"TerminateSteadyState(abstol = 1e-8, reltol = 1e-6, test = allDerivPass; min_t = nothing,\n    wrap_test::Val = Val(true))\n\nTerminateSteadyState can be used to solve the problem for the steady-state by running the solver until the derivatives of the problem converge to 0 or tspan[2] is reached. This is an alternative approach to root finding (see the Steady State Solvers section).\n\nArguments\n\nabstol and reltol are the absolute and relative tolerance, respectively. These tolerances may be specified as scalars or as arrays of the same length as the states of the problem.\ntest represents the function that evaluates the condition for termination. The default condition is that all derivatives should become smaller than abstol and the states times reltol. The user can pass any other function to implement a different termination condition. Such function should take four arguments: integrator, abstol, reltol, and min_t.\nwrap_test can be set to Val(false), in which case test must have the definition test(u, t, integrator). Otherwise, test must have the definition test(integrator, abstol, reltol, min_t).\n\nKeyword Arguments\n\nmin_t specifies an optional minimum t before the steady state calculations are allowed to terminate.\n\n\n\n\n\n","category":"function"},{"location":"projection/#Manifold-Projection","page":"Manifold Projection","title":"Manifold Projection","text":"","category":"section"},{"location":"projection/","page":"Manifold Projection","title":"Manifold Projection","text":"The following callbacks are designed to provide post-step modifications to preserve geometric behaviors in the solution.","category":"page"},{"location":"projection/","page":"Manifold Projection","title":"Manifold Projection","text":"ManifoldProjection","category":"page"},{"location":"projection/#DiffEqCallbacks.ManifoldProjection","page":"Manifold Projection","title":"DiffEqCallbacks.ManifoldProjection","text":"ManifoldProjection(g; nlsolve = NLSOLVEJL_SETUP(), save = true)\n\nIn many cases, you may want to declare a manifold on which a solution lives. Mathematically, a manifold M is defined by a function g as the set of points where g(u)=0. An embedded manifold can be a lower dimensional object which constrains the solution. For example, g(u)=E(u)-C where E is the energy of the system in state u, meaning that the energy must be constant (energy preservation). Thus by defining the manifold the solution should live on, you can retain desired properties of the solution.\n\nManifoldProjection projects the solution of the differential equation to the chosen manifold g, conserving a property while conserving the order. It is a consequence of convergence proofs both in the deterministic and stochastic cases that post-step projection to manifolds keep the same convergence rate, thus any algorithm can be easily extended to conserve properties. If the solution is supposed to live on a specific manifold or conserve such property, this guarantees the conservation law without modifying the convergence properties.\n\nArguments\n\ng: The residual function for the manifold. This is an inplace function of form g(resid, u) or g(resid, u, p, t) which writes to the residual resid the difference from the manifold components. Here, it is assumed that resid is of the same shape as u.\n\nKeyword Arguments\n\nnlsolve: A nonlinear solver as defined in the nlsolve format\nsave: Whether to do the standard saving (applied after the callback)\nautonomous: Whether g is an autonomous function of the form g(resid, u).\nnlopts: Optional arguments to nonlinear solver which can be any of the NLsolve keywords.\n\nSaveat Warning\n\nNote that the ManifoldProjection callback modifies the endpoints of the integration intervals and thus breaks assumptions of internal interpolations. Because of this, the values for given by saveat will not be order-matching. However, the interpolation error can be proportional to the change by the projection, so if the projection is making small changes then one is still safe. However, if there are large changes from each projection, you should consider only saving at stopping/projection times. To do this, set tstops to the same values as saveat. There is a performance hit by doing so because now the integrator is forced to stop at every saving point, but this is guerenteed to match the order of the integrator even with the ManifoldProjection.\n\nReferences\n\nErnst Hairer, Christian Lubich, Gerhard Wanner. Geometric Numerical Integration: Structure-Preserving Algorithms for Ordinary Differential Equations. Berlin ; New York :Springer, 2002.\n\n\n\n\n\n","category":"type"},{"location":"projection/#Example","page":"Manifold Projection","title":"Example","text":"","category":"section"},{"location":"projection/","page":"Manifold Projection","title":"Manifold Projection","text":"Here we solve the harmonic oscillator:","category":"page"},{"location":"projection/","page":"Manifold Projection","title":"Manifold Projection","text":"using OrdinaryDiffEq, DiffEqCallbacks, Plots\n\nu0 = ones(2)\nfunction f(du, u, p, t)\n    du[1] = u[2]\n    du[2] = -u[1]\nend\nprob = ODEProblem(f, u0, (0.0, 100.0))","category":"page"},{"location":"projection/","page":"Manifold Projection","title":"Manifold Projection","text":"However, this problem is supposed to conserve energy, and thus we define our manifold to conserve the sum of squares:","category":"page"},{"location":"projection/","page":"Manifold Projection","title":"Manifold Projection","text":"function g(resid, u, p, t)\n    resid[1] = u[2]^2 + u[1]^2 - 2\n    resid[2] = 0\nend","category":"page"},{"location":"projection/","page":"Manifold Projection","title":"Manifold Projection","text":"To build the callback, we just call","category":"page"},{"location":"projection/","page":"Manifold Projection","title":"Manifold Projection","text":"cb = ManifoldProjection(g)","category":"page"},{"location":"projection/","page":"Manifold Projection","title":"Manifold Projection","text":"Using this callback, the Runge-Kutta method Vern7 conserves energy. Note that the standard saving occurs after the step and before the callback, and thus we set save_everystep=false to turn off all standard saving and let the callback save after the projection is applied.","category":"page"},{"location":"projection/","page":"Manifold Projection","title":"Manifold Projection","text":"sol = solve(prob, Vern7(), save_everystep = false, callback = cb)\n@show sol[end][1]^2 + sol[end][2]^2 ≈ 2","category":"page"},{"location":"projection/","page":"Manifold Projection","title":"Manifold Projection","text":"using Plots\nplot(sol, idxs = (1, 2))","category":"page"},{"location":"step_control/#Step-Control-Callbacks","page":"Step Control Callbacks","title":"Step Control Callbacks","text":"","category":"section"},{"location":"step_control/","page":"Step Control Callbacks","title":"Step Control Callbacks","text":"The following callbacks allow for more refined controls of stepping behavior, allowing for preserving geometric properties and precise error definitions.","category":"page"},{"location":"step_control/","page":"Step Control Callbacks","title":"Step Control Callbacks","text":"StepsizeLimiter\nGeneralDomain\nPositiveDomain\nAutoAbstol","category":"page"},{"location":"step_control/#DiffEqCallbacks.StepsizeLimiter","page":"Step Control Callbacks","title":"DiffEqCallbacks.StepsizeLimiter","text":"StepsizeLimiter(dtFE;safety_factor=9//10,max_step=false,cached_dtcache=0.0)\n\nIn many cases, there is a known maximal stepsize for which the computation is stable and produces correct results. For example, in hyperbolic PDEs one normally needs to ensure that the stepsize stays below some Delta t_FE determined by the CFL condition. For nonlinear hyperbolic PDEs this limit can be a function dtFE(u,p,t) which changes throughout the computation. The stepsize limiter lets you pass a function which will adaptively limit the stepsizes to match these constraints.\n\nArguments\n\ndtFE is the maximal timestep and is calculated using the previous t and u.\n\nKeyword Arguments\n\nsafety_factor is the factor below the true maximum that will be stepped to which defaults to 9//10.\nmax_step=true makes every step equal to safety_factor*dtFE(u,p,t) when the solver is set to adaptive=false.\ncached_dtcache should be set to match the type for time when not using Float64 values.\n\n\n\n\n\n","category":"function"},{"location":"step_control/#DiffEqCallbacks.GeneralDomain","page":"Step Control Callbacks","title":"DiffEqCallbacks.GeneralDomain","text":"GeneralDomain(g, u = nothing; nlsolve = NLSOLVEJL_SETUP(), save = true,\n    abstol = nothing, scalefactor = nothing,\n    autonomous = maximum(SciMLBase.numargs(g)) == 3,\n    nlopts = Dict(:ftol => 10 * eps()))\n\nA GeneralDomain callback in DiffEqCallbacks.jl generalizes the concept of a PositiveDomain callback to arbitrary domains. Domains are specified by in-place functions g(resid, u, p) or g(resid, u, p, t) that calculate residuals of a state vector u at time t relative to that domain, with p the parameters of the corresponding integrator. As for PositiveDomain, steps are accepted if residuals of the extrapolated values at the next time step are below a certain tolerance. Moreover, this callback is automatically coupled with a ManifoldProjection that keeps all calculated state vectors close to the desired domain, but in contrast to a PositiveDomain callback the nonlinear solver in a ManifoldProjection cannot guarantee that all state vectors of the solution are actually inside the domain. Thus, a PositiveDomain callback should generally be preferred.\n\nArguments\n\ng: the implicit definition of the domain as a function g(resid, u, p) or g(resid, u, p, t) which is zero when the value is in the domain.\nu: A prototype of the state vector of the integrator. A copy of it is saved and extrapolated values are written to it. If it is not specified, every application of the callback allocates a new copy of the state vector.\n\nKeyword Arguments\n\nnlsolve: A nonlinear solver as defined in the nlsolve format which is passed to a ManifoldProjection.\nsave: Whether to do the standard saving (applied after the callback).\nabstol: Tolerance up to, which residuals are accepted. Element-wise tolerances are allowed. If it is not specified, every application of the callback uses the current absolute tolerances of the integrator.\nscalefactor: Factor by which an unaccepted time step is reduced. If it is not specified, time steps are halved.\nautonomous: Whether g is an autonomous function of the form g(resid, u, p).\nnlopts: Optional arguments to nonlinear solver of a ManifoldProjection which can be any of the NLsolve keywords. The default value of ftol = 10*eps() ensures that convergence is only declared if the infinite norm of residuals is very small and hence the state vector is very close to the domain.\n\nReferences\n\nShampine, Lawrence F., Skip Thompson, Jacek Kierzenka and G. D. Byrne. Non-negative solutions of ODEs. Applied Mathematics and Computation 170 (2005): 556-569.\n\n\n\n\n\n","category":"function"},{"location":"step_control/#DiffEqCallbacks.PositiveDomain","page":"Step Control Callbacks","title":"DiffEqCallbacks.PositiveDomain","text":"PositiveDomain(u = nothing; save = true, abstol = nothing, scalefactor = nothing)\n\nEspecially in biology and other natural sciences, a desired property of dynamical systems is the positive invariance of the positive cone, i.e. non-negativity of variables at time t_0 ensures their non-negativity at times t geq t_0 for which the solution is defined. However, even if a system satisfies this property mathematically it can be difficult for ODE solvers to ensure it numerically, as these MATLAB examples show.\n\nTo deal with this problem, one can specify isoutofdomain=(u,p,t) -> any(x -> x < 0, u) as additional solver option, which will reject any step that leads to non-negative values and reduce the next time step. However, since this approach only rejects steps and hence calculations might be repeated multiple times until a step is accepted, it can be computationally expensive.\n\nAnother approach is taken by a PositiveDomain callback in DiffEqCallbacks.jl, which is inspired by Shampine's et al. paper about non-negative ODE solutions. It reduces the next step by a certain scale factor until the extrapolated value at the next time point is non-negative with a certain tolerance. Extrapolations are cheap to compute but might be inaccurate, so if a time step is changed it is additionally reduced by a safety factor of 0.9. Since extrapolated values are only non-negative up to a certain tolerance and in addition actual calculations might lead to negative values, also any negative values at the current time point are set to 0. Hence, by this callback non-negative values at any time point are ensured in a computationally cheap way, but the quality of the solution depends on how accurately extrapolations approximate next time steps.\n\nPlease note, that the system should be defined also outside the positive domain, since even with these approaches, negative variables might occur during the calculations. Moreover, one should follow Shampine's et al. advice and set the derivative x_i of a negative component x_i to max 0 f_i(x t), where t denotes the current time point with state vector x and f_i is the i-th component of function f in an ODE system x = f(x t).\n\nArguments\n\nu: A prototype of the state vector of the integrator. A copy of it is saved and extrapolated values are written to it. If it is not specified, every application of the callback allocates a new copy of the state vector.\n\nKeyword Arguments\n\nsave: Whether to do the standard saving (applied after the callback).\nabstol: Tolerance up to, which negative extrapolated values are accepted. Element-wise tolerances are allowed. If it is not specified, every application of the callback uses the current absolute tolerances of the integrator.\nscalefactor: Factor by which an unaccepted time step is reduced. If it is not specified, time steps are halved.\n\nReferences\n\nShampine, Lawrence F., Skip Thompson, Jacek Kierzenka and G. D. Byrne. Non-negative solutions of ODEs. Applied Mathematics and Computation 170 (2005): 556-569.\n\n\n\n\n\n","category":"function"},{"location":"step_control/#DiffEqCallbacks.AutoAbstol","page":"Step Control Callbacks","title":"DiffEqCallbacks.AutoAbstol","text":"AutoAbstol(save = true; init_curmax = 1e-6)\n\nProvides a way to automatically adapt the absolute tolerance to the problem. This helps the solvers automatically “learn” what appropriate limits are. This callback set starts the absolute tolerance at init_curmax (default 1e-6), and at each iteration it is set to the maximum value that the state has thus far reached times the relative tolerance.\n\nKeyword Arguments\n\nsave determines whether this callback has saving enabled\ninit_curmax is the initial abstol.\n\nIf this callback is used in isolation, save=true is required for normal saving behavior. Otherwise, save=false should be set to ensure extra saves do not occur.\n\n\n\n\n\n","category":"function"},{"location":"output_saving/#Output-and-Saving-Controls","page":"Output and Saving Controls","title":"Output and Saving Controls","text":"","category":"section"},{"location":"output_saving/","page":"Output and Saving Controls","title":"Output and Saving Controls","text":"These callbacks extend the output and saving controls available during time stepping.","category":"page"},{"location":"output_saving/","page":"Output and Saving Controls","title":"Output and Saving Controls","text":"SavingCallback\nFunctionCallingCallback","category":"page"},{"location":"output_saving/#DiffEqCallbacks.SavingCallback","page":"Output and Saving Controls","title":"DiffEqCallbacks.SavingCallback","text":"SavingCallback(save_func, saved_values::SavedValues;\n    saveat = Vector{eltype(saved_values.t)}(),\n    save_everystep = isempty(saveat),\n    save_start = true,\n    tdir = 1)\n\nThe saving callback lets you define a function save_func(u, t, integrator) which returns quantities of interest that shall be saved.\n\nArguments\n\nsave_func(u, t, integrator) returns the quantities which shall be saved. Note that this should allocate the output (not as a view to u).\nsaved_values::SavedValues is the types that save_func will return, i.e. save_func(t, u, integrator)::savevalType. It's specified via SavedValues(typeof(t),savevalType), i.e. give the type for time and the type that save_func will output (or higher compatible type).\n\nKeyword Arguments\n\nsaveat mimics saveat in solve from solve.\nsave_everystep mimics save_everystep from solve.\nsave_start mimics save_start from solve.\nsave_end mimics save_end from solve.\ntdir should be sign(tspan[end]-tspan[1]). It defaults to 1 and should be adapted if tspan[1] > tspan[end].\n\nThe outputted values are saved into saved_values. Time points are found via saved_values.t and the values are saved_values.saveval.\n\n\n\n\n\n","category":"function"},{"location":"output_saving/#DiffEqCallbacks.FunctionCallingCallback","page":"Output and Saving Controls","title":"DiffEqCallbacks.FunctionCallingCallback","text":"FunctionCallingCallback(func;\n    funcat = Vector{Float64}(),\n    func_everystep = isempty(funcat),\n    func_start = true,\n    tdir = 1)\n\nThe function calling callback lets you define a function func(u,t,integrator) which gets calls at the time points of interest. The constructor is:\n\nfunc(u, t, integrator) is the function to be called.\nfuncat values or interval that the function is sure to be evaluated at.\nfunc_everystep whether to call the function after each integrator step.\nfunc_start whether the function is called the initial condition.\ntdir should be sign(tspan[end]-tspan[1]). It defaults to 1 and should be adapted if tspan[1] > tspan[end].\n\n\n\n\n\n","category":"function"},{"location":"output_saving/#Saving-Example","page":"Output and Saving Controls","title":"Saving Example","text":"","category":"section"},{"location":"output_saving/","page":"Output and Saving Controls","title":"Output and Saving Controls","text":"In this example, we will solve a matrix equation and at each step save a tuple of values which contains the current trace and the norm of the matrix. We build the SavedValues cache to use Float64 for time and Tuple{Float64,Float64} for the saved values, and then call the solver with the callback.","category":"page"},{"location":"output_saving/","page":"Output and Saving Controls","title":"Output and Saving Controls","text":"using DiffEqCallbacks, OrdinaryDiffEq, LinearAlgebra\nprob = ODEProblem((du, u, p, t) -> du .= u, rand(4, 4), (0.0, 1.0))\nsaved_values = SavedValues(Float64, Tuple{Float64, Float64})\ncb = SavingCallback((u, t, integrator) -> (tr(u), norm(u)), saved_values)\nsol = solve(prob, Tsit5(), callback = cb)\n\nprint(saved_values.saveval)","category":"page"},{"location":"output_saving/","page":"Output and Saving Controls","title":"Output and Saving Controls","text":"Note that the values are retrieved from the cache as .saveval, and the time points are found as .t. If we want to control the saved times, we use saveat in the callback. The save controls like saveat act analogously to how they act in the solve function.","category":"page"},{"location":"output_saving/","page":"Output and Saving Controls","title":"Output and Saving Controls","text":"saved_values = SavedValues(Float64, Tuple{Float64, Float64})\ncb = SavingCallback((u, t, integrator) -> (tr(u), norm(u)), saved_values,\n    saveat = 0.0:0.1:1.0)\nsol = solve(prob, Tsit5(), callback = cb)\nprint(saved_values.saveval)\nprint(saved_values.t)","category":"page"},{"location":"timed_callbacks/#Timed-Callbacks","page":"Timed Callbacks","title":"Timed Callbacks","text":"","category":"section"},{"location":"timed_callbacks/","page":"Timed Callbacks","title":"Timed Callbacks","text":"The following callbacks are designed to help build callbacks with specific timing schemes for when the affect! is to be detonated.","category":"page"},{"location":"timed_callbacks/","page":"Timed Callbacks","title":"Timed Callbacks","text":"PresetTimeCallback\nPeriodicCallback\nIterativeCallback","category":"page"},{"location":"timed_callbacks/#DiffEqCallbacks.PresetTimeCallback","page":"Timed Callbacks","title":"DiffEqCallbacks.PresetTimeCallback","text":"PresetTimeCallback(tstops, user_affect!;\n    initialize = DiffEqBase.INITIALIZE_DEFAULT,\n    filter_tstops = true,\n    kwargs...)\n\nA callback that adds callback affect! calls at preset times. No playing around with tstops or anything is required: this callback adds the triggers for you to make it automatic.\n\nArguments\n\ntstops: the times for the affect! to trigger at.\nuser_affect!: an affect!(integrator) function to use at the time points.\n\nKeyword Arguments\n\nfilter_tstops: Whether to filter out tstops beyond the end of the integration timespan. Defaults to true. If false, then tstops can extend the interval of integration.\n\n\n\n\n\n","category":"function"},{"location":"timed_callbacks/#DiffEqCallbacks.PeriodicCallback","page":"Timed Callbacks","title":"DiffEqCallbacks.PeriodicCallback","text":"PeriodicCallback(f, Δt::Number; initial_affect = false,\n    final_affect = false,\n    kwargs...)\n\nPeriodicCallback can be used when a function should be called periodically in terms of integration time (as opposed to wall time), i.e. at t = tspan[1], t = tspan[1] + Δt, t = tspan[1] + 2Δt, and so on. This callback can, for example, be used to model a discrete-time controller for a continuous-time system, running at a fixed rate.\n\nArguments\n\nf the affect!(integrator) function to be called periodically\nΔt is the period\n\nKeyword Arguments\n\ninitial_affect is whether to apply the affect at t=0, which defaults to false\nfinal_affect is whether to apply the affect at the final time, which defaults to false\nkwargs are keyword arguments accepted by the DiscreteCallback constructor.\n\n\n\n\n\n","category":"function"},{"location":"timed_callbacks/#DiffEqCallbacks.IterativeCallback","page":"Timed Callbacks","title":"DiffEqCallbacks.IterativeCallback","text":"IterativeCallback(time_choice, user_affect!, tType = Float64;\n    initial_affect = false, kwargs...)\n\nA callback to be used to iteratively apply some affect. For example, if given the first effect at t₁, you can define t₂ to apply the next effect.\n\nArguments\n\ntime_choice(integrator) determines the time of the next callback. If nothing is returned for the time choice, then the iterator ends.\nuser_affect! is the effect applied to the integrator at the stopping points.\n\nKeyword Arguments\n\ninitial_affect is whether to apply the affect at t=0 which defaults to false\n\n\n\n\n\n","category":"function"},{"location":"#DiffEqCallbacks.jl:-Prebuilt-Callbacks-for-extending-the-solvers-of-DifferentialEquations.jl","page":"Home","title":"DiffEqCallbacks.jl: Prebuilt Callbacks for extending the solvers of DifferentialEquations.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"DifferentialEquations.jl has an expressive callback system which allows for customizable transformations of the solver behavior. DiffEqCallbacks.jl is a library of pre-built callbacks which makes it easy to transform the solver into a domain-specific simulation tool.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install DiffEqCallbacks.jl, use the Julia package manager:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"DiffEqCallbacks\")","category":"page"},{"location":"#Usage","page":"Home","title":"Usage","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To use the callbacks provided in this library with solvers, simply pass the callback to the solver via the callback keyword argument:","category":"page"},{"location":"","page":"Home","title":"Home","text":"sol = solve(prob, alg; callback = cb)","category":"page"},{"location":"","page":"Home","title":"Home","text":"For more information on using callbacks, see the manual page.","category":"page"},{"location":"#Note-About-Dependencies","page":"Home","title":"Note About Dependencies","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Note that DiffEqCallbacks.jl is not a required dependency for the callback mechanism. DiffEqCallbacks.jl is simply a library of pre-made callbacks, not the library which defines the callback system. Callbacks are defined in the SciML interface at SciMLBase.jl.","category":"page"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to SciML.\nSee the SciML Style Guide for common coding practices and other style decisions.\nThere are a few community forums:\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Slack\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Zulip\nOn the Julia Discourse forums\nSee also SciML Community page","category":"page"},{"location":"#Reproducibility","page":"Home","title":"Reproducibility","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"<details><summary>The documentation of this SciML package was built using these direct dependencies,</summary>","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg # hide\nPkg.status() # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"</details>","category":"page"},{"location":"","page":"Home","title":"Home","text":"<details><summary>and using this machine and Julia version.</summary>","category":"page"},{"location":"","page":"Home","title":"Home","text":"using InteractiveUtils # hide\nversioninfo() # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"</details>","category":"page"},{"location":"","page":"Home","title":"Home","text":"<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg # hide\nPkg.status(; mode = PKGMODE_MANIFEST) # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"</details>","category":"page"},{"location":"","page":"Home","title":"Home","text":"using TOML\nusing Markdown\nversion = TOML.parse(read(\"../../Project.toml\", String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\", String))[\"name\"]\nlink_manifest = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n                \"/assets/Manifest.toml\"\nlink_project = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n               \"/assets/Project.toml\"\nMarkdown.parse(\"\"\"You can also download the\n[manifest]($link_manifest)\nfile and the\n[project]($link_project)\nfile.\n\"\"\")","category":"page"}]
}
